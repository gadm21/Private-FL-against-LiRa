
@article{wuCommunicationefficientFederatedLearning2022,
	title = {Communication-efficient federated learning via knowledge distillation},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-29763-x},
	doi = {10.1038/s41467-022-29763-x},
	abstract = {Federated learning is a privacy-preserving machine learning technique to train intelligent models from decentralized data, which enables exploiting private data by communicating local model updates in each iteration of model learning rather than the raw data. However, model updates can be extremely large if they contain numerous parameters, and many rounds of communication are needed for model training. The huge communication cost in federated learning leads to heavy overheads on clients and high environmental burdens. Here, we present a federated learning method named FedKD that is both communication-efficient and effective, based on adaptive mutual knowledge distillation and dynamic gradient compression techniques. FedKD is validated on three different scenarios that need privacy protection, showing that it maximally can reduce 94.89\% of communication cost and achieve competitive results with centralized model learning. FedKD provides a potential to efficiently deploy privacy-preserving intelligent systems in many scenarios, such as intelligent healthcare and personalization.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {Nature Communications},
	author = {Wu, Chuhan and Wu, Fangzhao and Lyu, Lingjuan and Huang, Yongfeng and Xie, Xing},
	month = apr,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Machine learning},
	pages = {2032},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/48EGHLVJ/Wu et al. - 2022 - Communication-efficient federated learning via kno.pdf:application/pdf;Snapshot:/Users/gadmohamed/Zotero/storage/N32G5Z7S/s41467-022-29763-x.html:text/html},
}

@inproceedings{linDeepGradientCompression2022,
	title = {Deep {Gradient} {Compression}: {Reducing} the {Communication} {Bandwidth} for {Distributed} {Training}},
	shorttitle = {Deep {Gradient} {Compression}},
	url = {https://openreview.net/forum?id=SkhQHMW0W},
	abstract = {we find 99.9\% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy.},
	language = {en},
	urldate = {2022-08-31},
	author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, Bill},
	month = feb,
	year = {2022},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/ZSJZK89X/Lin et al. - 2022 - Deep Gradient Compression Reducing the Communicat.pdf:application/pdf;Snapshot:/Users/gadmohamed/Zotero/storage/HLKW692L/forum.html:text/html},
}

@article{rajkomarScalableAccurateDeep2018,
	title = {Scalable and accurate deep learning with electronic health records},
	volume = {1},
	copyright = {2018 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-018-0029-1%22},
	doi = {10.1038/s41746-018-0029-1},
	abstract = {Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient’s record. We propose a representation of patients’ entire raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two US academic medical centers with 216,221 adult patients hospitalized for at least 24 h. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting: in-hospital mortality (area under the receiver operator curve [AUROC] across sites 0.93–0.94), 30-day unplanned readmission (AUROC 0.75–0.76), prolonged length of stay (AUROC 0.85–0.86), and all of a patient’s final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed traditional, clinically-used predictive models in all cases. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios. In a case study of a particular prediction, we demonstrate that neural networks can be used to identify relevant information from the patient’s chart.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {npj Digital Medicine},
	author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Hardt, Michaela and Liu, Peter J. and Liu, Xiaobing and Marcus, Jake and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Zhang, Yi and Flores, Gerardo and Duggan, Gavin E. and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael D. and Cui, Claire and Corrado, Greg S. and Dean, Jeffrey},
	month = may,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Machine learning, Medical research},
	pages = {1--10},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/5RD54R5Z/Rajkomar et al. - 2018 - Scalable and accurate deep learning with electroni.pdf:application/pdf;Snapshot:/Users/gadmohamed/Zotero/storage/R85KI27X/s41746-018-0029-1.html:text/html},
}

@inproceedings{wangNeuralGraphCollaborative2019,
	address = {New York, NY, USA},
	series = {{SIGIR}'19},
	title = {Neural {Graph} {Collaborative} {Filtering}},
	isbn = {978-1-4503-6172-9},
	url = {https://doi.org/10.1145/3331184.3331267},
	doi = {10.1145/3331184.3331267},
	abstract = {Learning vector representations (aka. embeddings) of users and items lies at the core of modern recommender systems. Ranging from early matrix factorization to recently emerged deep learning based methods, existing efforts typically obtain a user's (or an item's) embedding by mapping from pre-existing features that describe the user (or the item), such as ID and attributes. We argue that an inherent drawback of such methods is that, the collaborative signal, which is latent in user-item interactions, is not encoded in the embedding process. As such, the resultant embeddings may not be sufficient to capture the collaborative filtering effect. In this work, we propose to integrate the user-item interactions - more specifically the bipartite graph structure - into the embedding process. We develop a new recommendation framework Neural Graph Collaborative Filtering (NGCF), which exploits the user-item graph structure by propagating embeddings on it. This leads to the expressive modeling of high-order connectivity in user-item graph, effectively injecting the collaborative signal into the embedding process in an explicit manner. We conduct extensive experiments on three public benchmarks, demonstrating significant improvements over several state-of-the-art models like HOP-Rec [39] and Collaborative Memory Network [5]. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectiveness of NGCF. Codes are available at https://github.com/xiangwang1223/neural\_graph\_collaborative\_filtering.},
	urldate = {2022-08-30},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xiang and He, Xiangnan and Wang, Meng and Feng, Fuli and Chua, Tat-Seng},
	month = jul,
	year = {2019},
	keywords = {collaborative filtering, embedding propagation, graph neural network, high-order connectivity, recommendation},
	pages = {165--174},
	file = {Submitted Version:/Users/gadmohamed/Zotero/storage/W98JSV2F/Wang et al. - 2019 - Neural Graph Collaborative Filtering.pdf:application/pdf},
}

@article{riekeFutureDigitalHealth2020,
	title = {The future of digital health with federated learning},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00323-1},
	doi = {10.1038/s41746-020-00323-1},
	abstract = {Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {npj Digital Medicine},
	author = {Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletarì, Fausto and Roth, Holger R. and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N. and Landman, Bennett A. and Maier-Hein, Klaus and Ourselin, Sébastien and Sheller, Micah and Summers, Ronald M. and Trask, Andrew and Xu, Daguang and Baust, Maximilian and Cardoso, M. Jorge},
	month = sep,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Medical research, Medical imaging},
	pages = {1--7},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/SHJ3ZW6X/Rieke et al. - 2020 - The future of digital health with federated learni.pdf:application/pdf;Snapshot:/Users/gadmohamed/Zotero/storage/7FRYLDUN/s41746-020-00323-1.html:text/html},
}

@inproceedings{mcmahanCommunicationefficientLearningDeep2017,
	title = {Communication-efficient learning of deep networks from decentralized data},
	booktitle = {Artificial intelligence and statistics},
	publisher = {PMLR},
	author = {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
	year = {2017},
	pages = {1273--1282},
}

@misc{linDeepGradientCompression2020,
	title = {Deep {Gradient} {Compression}: {Reducing} the {Communication} {Bandwidth} for {Distributed} {Training}},
	shorttitle = {Deep {Gradient} {Compression}},
	url = {http://arxiv.org/abs/1712.01887},
	doi = {10.48550/arXiv.1712.01887},
	abstract = {Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training, and requires expensive high-bandwidth network infrastructure. The situation gets even worse with distributed training on mobile devices (federated learning), which suffers from higher latency, lower throughput, and intermittent poor connections. In this paper, we find 99.9\% of the gradient exchange in distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to greatly reduce the communication bandwidth. To preserve accuracy during compression, DGC employs four methods: momentum correction, local gradient clipping, momentum factor masking, and warm-up training. We have applied Deep Gradient Compression to image classification, speech recognition, and language modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and Librispeech Corpus. On these scenarios, Deep Gradient Compression achieves a gradient compression ratio from 270x to 600x without losing accuracy, cutting the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from 488MB to 0.74MB. Deep gradient compression enables large-scale distributed training on inexpensive commodity 1Gbps Ethernet and facilitates distributed training on mobile. Code is available at: https://github.com/synxlin/deep-gradient-compression.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J.},
	month = jun,
	year = {2020},
	note = {arXiv:1712.01887 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: we find 99.9\% of the gradient exchange in distributed SGD is redundant; we reduce the communication bandwidth by two orders of magnitude without losing accuracy. Code is available at: https://github.com/synxlin/deep-gradient-compression},
	file = {arXiv Fulltext PDF:/Users/gadmohamed/Zotero/storage/KYSLG4LP/Lin et al. - 2020 - Deep Gradient Compression Reducing the Communicat.pdf:application/pdf;arXiv.org Snapshot:/Users/gadmohamed/Zotero/storage/3TJYI92G/1712.html:text/html},
}

@misc{wilhelmiMachineLearningPerformance2021,
	title = {Machine {Learning} for {Performance} {Prediction} of {Channel} {Bonding} in {Next}-{Generation} {IEEE} 802.11 {WLANs}},
	url = {http://arxiv.org/abs/2105.14219},
	doi = {10.48550/arXiv.2105.14219},
	abstract = {With the advent of Artificial Intelligence (AI)-empowered communications, industry, academia, and standardization organizations are progressing on the definition of mechanisms and procedures to address the increasing complexity of future 5G and beyond communications. In this context, the International Telecommunication Union (ITU) organized the first AI for 5G Challenge to bring industry and academia together to introduce and solve representative problems related to the application of Machine Learning (ML) to networks. In this paper, we present the results gathered from Problem Statement{\textasciitilde}13 (PS-013), organized by Universitat Pompeu Fabra (UPF), which primary goal was predicting the performance of next-generation Wireless Local Area Networks (WLANs) applying Channel Bonding (CB) techniques. In particular, we overview the ML models proposed by participants (including Artificial Neural Networks, Graph Neural Networks, Random Forest regression, and gradient boosting) and analyze their performance on an open dataset generated using the IEEE 802.11ax-oriented Komondor network simulator. The accuracy achieved by the proposed methods demonstrates the suitability of ML for predicting the performance of WLANs. Moreover, we discuss the importance of abstracting WLAN interactions to achieve better results, and we argue that there is certainly room for improvement in throughput prediction through ML.},
	urldate = {2022-09-01},
	publisher = {arXiv},
	author = {Wilhelmi, Francesc and Góez, David and Soto, Paola and Vallés, Ramon and Alfaifi, Mohammad and Algunayah, Abdulrahman and Martin-Pérez, Jorge and Girletti, Luigi and Mohan, Rajasekar and Ramnan, K. Venkat and Bellalta, Boris},
	month = may,
	year = {2021},
	note = {arXiv:2105.14219 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Networking and Internet Architecture},
	file = {arXiv Fulltext PDF:/Users/gadmohamed/Zotero/storage/MRG7KHZY/Wilhelmi et al. - 2021 - Machine Learning for Performance Prediction of Cha.pdf:application/pdf;arXiv.org Snapshot:/Users/gadmohamed/Zotero/storage/T6C6RWSJ/2105.html:text/html},
}

@article{ohMix2FLDDownlinkFederated2020,
	title = {{Mix2FLD}: {Downlink} {Federated} {Learning} {After} {Uplink} {Federated} {Distillation} {With} {Two}-{Way} {Mixup}},
	volume = {24},
	issn = {1558-2558},
	shorttitle = {{Mix2FLD}},
	doi = {10.1109/LCOMM.2020.3003693},
	abstract = {This letter proposes a novel communication-efficient and privacy-preserving distributed machine learning framework, coined Mix2FLD. To address uplink-downlink capacity asymmetry, local model outputs are uploaded to a server in the uplink as in federated distillation (FD), whereas global model parameters are downloaded in the downlink as in federated learning (FL). This requires a model output-to-parameter conversion at the server, after collecting additional data samples from devices. To preserve privacy while not compromising accuracy, linearly mixed-up local samples are uploaded, and inversely mixed up across different devices at the server. Numerical evaluations show that Mix2FLD achieves up to 16.7\% higher test accuracy while reducing convergence time by up to 18.8\% under asymmetric uplink-downlink channels compared to FL.},
	number = {10},
	journal = {IEEE Communications Letters},
	author = {Oh, Seungeun and Park, Jihong and Jeong, Eunjeong and Kim, Hyesung and Bennis, Mehdi and Kim, Seong-Lyun},
	month = oct,
	year = {2020},
	note = {Conference Name: IEEE Communications Letters},
	keywords = {Collaborative work, Data models, Data privacy, Distributed machine learning, Downlink, federated distillation, federated learning, on-device learning, Servers, Uplink, uplink-downlink asymmetry, Wireless communication},
	pages = {2211--2215},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/CRVCAJPB/9121290.html:text/html;Submitted Version:/Users/gadmohamed/Zotero/storage/DYXVFSI4/Oh et al. - 2020 - Mix2FLD Downlink Federated Learning After Uplink .pdf:application/pdf},
}

@misc{alMix2FLDDownlinkFederated,
	title = {{Mix2FLD}: {Downlink} {Federated} {Learning} {After} {Uplink} {Federated} {Distillation} {With} {Two}-{Way} {Mixup} {\textbar} {EndNote} {Click}},
	shorttitle = {{Mix2FLD}},
	url = {https://click.endnote.com/viewer?doi=10.1109%2Flcomm.2020.3003693&token=WzM4MTExMDksIjEwLjExMDkvbGNvbW0uMjAyMC4zMDAzNjkzIl0.9aUR0bUDxS2U4t6fkUDIEbv1WzU},
	abstract = {Download PDF of Mix2FLD: Downlink Federated Learning After Uplink Federated Distillation With Two-Way Mixup published in IEEE Communications Letters},
	language = {en},
	urldate = {2022-10-02},
	author = {al, S. Oh et},
	file = {Snapshot:/Users/gadmohamed/Zotero/storage/Z2453A2Z/viewer.html:text/html},
}

@article{wangDeepLearningSensorbased2019,
	title = {Deep learning for sensor-based activity recognition: {A} survey},
	volume = {119},
	copyright = {2018 Elsevier B.V.},
	issn = {0167-8655},
	abstract = {•We survey deep learning based HAR in sensor modality, deep model, and application.•We comprehensively discuss the insights of deep learning models for HAR tasks.•We extensively investigate why deep learning can improve the performance of HAR.•We also summarize the public HAR datasets frequently used for research purpose.•We present some grand challenges and feasible solutions for deep learning based HAR. Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. Additionally, existing methods are undermined for unsupervised and incremental learning tasks. Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. This paper surveys the recent advance of deep learning based sensor-based activity recognition. We summarize existing literature from three aspects: sensor modality, deep model, and application. We also present detailed insights on existing work and propose grand challenges for future research.},
	language = {eng},
	journal = {Pattern recognition letters},
	author = {Wang, Jindong and Chen, Yiqiang and Hao, Shuji and Peng, Xiaohui and Hu, Lisha},
	year = {2019},
	note = {Place: AMSTERDAM
Publisher: Elsevier B.V},
	keywords = {Activity recognition, Artificial Intelligence, Computer Science, Deep learning, Feature extraction, Heuristic methods, Levels, Pattern recognition, Pervasive computing, Science \& Technology, Sensors, Surveys, Technology},
	pages = {3--11},
}

@article{behjatiLoRaCommunicationsEnabler2021,
	title = {{LoRa} {Communications} as an {Enabler} for {Internet} of {Drones} towards {Large}-{Scale} {Livestock} {Monitoring} in {Rural} {Farms}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/15/5044},
	doi = {10.3390/s21155044},
	abstract = {Currently, smart farming is considered an effective solution to enhance the productivity of farms; thereby, it has recently received broad interest from service providers to offer a wide range of applications, from pest identification to asset monitoring. Although the emergence of digital technologies, such as the Internet of Things (IoT) and low-power wide-area networks (LPWANs), has led to significant advances in the smart farming industry, farming operations still need more efficient solutions. On the other hand, the utilization of unmanned aerial vehicles (UAVs), also known as drones, is growing rapidly across many civil application domains. This paper aims to develop a farm monitoring system that incorporates UAV, LPWAN, and IoT technologies to transform the current farm management approach and aid farmers in obtaining actionable data from their farm operations. In this regard, an IoT-based water quality monitoring system was developed because water is an essential aspect in livestock development. Then, based on the Long-Range Wide-Area Network (LoRaWAN®) technology, a multi-channel LoRaWAN® gateway was developed and integrated into a vertical takeoff and landing drone to convey collected data from the sensors to the cloud for further analysis. In addition, to develop LoRaWAN®-based aerial communication, a series of measurements and simulations were performed under different configurations and scenarios. Finally, to enhance the efficiency of aerial-based data collection, the UAV path planning was optimized. Measurement results showed that the maximum achievable LoRa coverage when operating on-air via the drone is about 10 km, and the Longley–Rice irregular terrain model provides the most suitable path loss model for the scenario of large-scale farms, and a multi-channel gateway with a spreading factor of 12 provides the most reliable communication link at a high drone speed (up to 95 km/h). Simulation results showed that the developed system can overcome the coverage limitation of LoRaWAN® and it can establish a reliable communication link over large-scale wireless sensor networks. In addition, it was shown that by optimizing flight paths, aerial data collection could be performed in a much shorter time than industrial mission planning (up to four times in our case).},
	language = {en},
	number = {15},
	urldate = {2022-11-24},
	journal = {Sensors},
	author = {Behjati, Mehran and Mohd Noh, Aishah Binti and Alobaidy, Haider A. H. and Zulkifley, Muhammad Aidiel and Nordin, Rosdiadee and Abdullah, Nor Fadzilah},
	month = jan,
	year = {2021},
	note = {Number: 15
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {drone, Internet of Things (IoT), long range (LoRa), path planning, remote sensing, smart farming, unmanned aircraft vehicle (UAV), wireless sensor network, lora-drone},
	pages = {5044},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/WU9FC4IS/Behjati et al. - 2021 - LoRa Communications as an Enabler for Internet of .pdf:application/pdf;Snapshot:/Users/gadmohamed/Zotero/storage/JGK5KJTN/5044.html:text/html},
}

@article{saraerehPerformanceEvaluationUAVEnabled2020,
	title = {Performance {Evaluation} of {UAV}-{Enabled} {LoRa} {Networks} for {Disaster} {Management} {Applications}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/8/2396},
	doi = {10.3390/s20082396},
	abstract = {In hostile and remote environments, such as mountains, forests or suburban areas, traditional communications may not be available, especially after a disaster, such as a flood, a forest fire or an earthquake. In these situations, the wireless networks may become congested or completely disrupted and may not be adequate to support the traffic generated by rescuers. It is also considered as the key tool in Corona Virus (COVID-19) battle. Moreover, the conventional approaches with fixed gateways may not work either, and this might lead to decoding errors due to the large distance between mobile nodes and the gateway. To avoid the decoding errors and improve the reliability of the messages, we propose to use intermediate Unmanned Aerial Vehicles (UAVs) to transfer messages from ground-based Long Range (LoRa) nodes to the remote base station (BS). Specifically, this UAV-enabled LoRa architecture is based on the ad hoc WiFi network, wherein, UAVs act as relays for the traffic generated between LoRa nodes and BS. To make the architecture more efficient, a distributed topology control algorithm is also proposed for UAVs. The algorithm is based on virtual spring forces and movement prediction technique that periodically updates the UAV topology to adapt to the movement of the ground-based LoRa nodes that move on the surface. The simulation results show the feasibility of the proposed approach for packet reception rate and average delay quality of service (QoS) metrics. It is observed that the mechanisms implemented in a UAV-enabled LoRa network effectively help to improve the packet reception rate with nominal buffer delays.},
	language = {en},
	number = {8},
	urldate = {2022-11-24},
	journal = {Sensors},
	author = {Saraereh, Omar A. and Alsaraira, Amer and Khan, Imran and Uthansakul, Peerapong},
	month = jan,
	year = {2020},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {lora-drone, LoRA, packet reception rate, topology control, UAV},
	pages = {2396},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/XZLB3K4U/Saraereh et al. - 2020 - Performance Evaluation of UAV-Enabled LoRa Network.pdf:application/pdf;Snapshot:/Users/gadmohamed/Zotero/storage/6QMAUFEU/2396.html:text/html},
}

@article{ghazaliSystematicReviewRealTime2021,
	title = {A {Systematic} {Review} of {Real}-{Time} {Deployments} of {UAV}-{Based} {LoRa} {Communication} {Network}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3110872},
	abstract = {The term Internet of Things (IoT) has emerged in recent decades because this network revolutionizes almost every aspect of our daily life, including products such as smartphones and intelligent vehicles, and crucial tasks such as precision agriculture and environmental monitoring. Myriads of communication technologies have been developed to fulfill the two main features of the IoT: long-range transmissions and low power consumption. Long-range (LoRa) has become one of the vital parts of IoT communication. In this study, the real-time deployments of an unmanned aerial vehicle (UAV)-based LoRa communication network are systematically reviewed, with a focus on the communication setup and its reported performance. Importantly, the UAV-based LoRa communication network has a low bit rate connectivity to ensure the high reliability of connections, especially in applications that require long transmission ranges. This study provides recommendations for researchers on what research perspectives need to be explored when implementing UAVs for IoT-based LoRa communication. This study also describes publication trends related to UAV-based LoRa communication networks. A supplementary Excel file that contains the reported publications on UAV-based LoRa communication networks is included to show this publication trend.},
	journal = {IEEE Access},
	author = {Ghazali, Mohamad Hazwan Mohd and Teoh, Kelvin and Rahiman, Wan},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Sensors, lora-drone, UAV, Communication networks, Internet of Things, IoT, Logic gates, LoRa, Market research, Monitoring, real-time, Real-time systems, wireless communication},
	pages = {124817--124830},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/ZITRDF4X/9530545.html:text/html;IEEE Xplore Full Text PDF:/Users/gadmohamed/Zotero/storage/8Y24HHMN/Ghazali et al. - 2021 - A Systematic Review of Real-Time Deployments of UA.pdf:application/pdf},
}

@article{singhInternetDronesPrecision2022,
	title = {The {Internet} of {Drones} in {Precision} {Agriculture}: {Challenges}, {Solutions}, and {Research} {Opportunities}},
	volume = {5},
	issn = {2576-3199},
	shorttitle = {The {Internet} of {Drones} in {Precision} {Agriculture}},
	doi = {10.1109/IOTM.006.2100100},
	abstract = {The Internet of Drones (IoD) is an emerging paradigm generated over the Internet of Things (IoT) framework, where things are replaced with drones. IoD facilitates inter-drone communication and provides a mechanism for automatically controlling the drones from a remote location, even in non-line-of-sight conditions. IoD also consists of the onboard controller for making smart decisions by using artificial intelligence. This article highlights the role of IoD in precision agriculture, which helps in achieving qualitative and quantitative improvement in agricultural products, improving the financial benefits of farmers and exact climate predictions. Next, we describe the different challenges and corresponding solutions that may be encountered while using IoD in precision agriculture. We also depict a taxonomy of these challenges and solutions. Finally, we discuss different research opportunities in IoD-based precision agriculture.},
	number = {1},
	journal = {IEEE Internet of Things Magazine},
	author = {Singh, Chitranjan and Mishra, Rahul and Gupta, Hari Prabhat and Kumari, Preti},
	month = mar,
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Magazine},
	keywords = {lora-drone, Internet of Things, Agricultural products, Artificial intelligence, Drones, Precision engineering, Taxonomy},
	pages = {180--184},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/VHGK9685/9773092.html:text/html},
}

@article{liDataHeterogeneityRobustFederated2022,
	title = {Data {Heterogeneity}-{Robust} {Federated} {Learning} via {Group} {Client} {Selection} in {Industrial} {IoT}},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2022.3161943},
	abstract = {Nowadays, the Industrial Internet of Things (IIoT) has played an integral role in Industry 4.0 and produced massive amounts of data for industrial intelligence. These data locate on decentralized devices in modern factories. To protect the confidentiality of industrial data, federated learning (FL) was introduced to collaboratively train shared machine learning (ML) models. However, the local data collected by different devices skew in class distribution and degrade industrial FL performance. This challenge has been widely studied at the mobile edge, but they ignored the rapidly changing streaming data and clustering nature of factory devices, and more seriously, they may threaten data security. In this article, we propose FED GS, which is a hierarchical cloud-edge-end FL framework for 5G empowered industries, to improve industrial FL performance on non-independent and identically distributed (non-j) data. Taking advantage of naturally clustered factory devices, FED GS uses a gradient-based binary permutation algorithm (GBP-CS) to select a subset of devices within each factory and build homogeneous super nodes participating in FL training. Then, we propose a compound-step synchronization protocol to coordinate the training process within and among these super nodes, which shows great robustness against data heterogeneity. The proposed methods are time-efficient and can adapt to dynamic environments, without exposing confidential industrial data in risky manipulation. We prove that FED GS has better convergence performance than FedAvg and give a relaxed condition under which FED GS is more communication efficient. The extensive experiments show that FED GS improves accuracy by 3.5\% and reduces training rounds by 59\% on average, confirming its superior effectiveness and efficiency on non-i.i.d. data.},
	number = {18},
	journal = {IEEE Internet of Things Journal},
	author = {Li, Zonghang and He, Yihong and Yu, Hongfang and Kang, Jiawen and Li, Xiaoping and Xu, Zenglin and Niyato, Dusit},
	month = sep,
	year = {2022},
	note = {Conference Name: IEEE Internet of Things Journal},
	keywords = {Data models, lora-drone, AI, client selection, cluster learning, Convergence, data heterogeneity, federated learning (FL), Industrial Internet of Things, Industrial Internet of Things (IIoT), Optical character recognition software, Production facilities, Synchronization, Training},
	pages = {17844--17857},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/NYKDUVLJ/9741255.html:text/html;Submitted Version:/Users/gadmohamed/Zotero/storage/4JZZNBNE/Li et al. - 2022 - Data Heterogeneity-Robust Federated Learning via G.pdf:application/pdf},
}

@misc{ZoteroGroups,
	title = {Zotero {\textbar} {Groups}},
	url = {https://www.zotero.org/groups},
	urldate = {2022-11-24},
	file = {Zotero | Groups:/Users/gadmohamed/Zotero/storage/NEQN74JH/groups.html:text/html},
}

@article{anguitaPublicDomainDataset2013,
	title = {A {Public} {Domain} {Dataset} for {Human} {Activity} {Recognition} {Using} {Smartphones}},
	abstract = {Human-centered computing is an emerging research ﬁeld that aims to understand human behavior and integrate users and their social context with computer systems. One of the most recent, challenging and appealing applications in this framework consists in sensing human body motion using smartphones to gather context information about people actions. In this context, we describe in this work an Activity Recognition database, built from the recordings of 30 subjects doing Activities of Daily Living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors, which is released to public domain on a well-known on-line repository. Results, obtained on the dataset by exploiting a multiclass Support Vector Machine (SVM), are also acknowledged.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier and Reyes-Ortiz, Jorge L},
	year = {2013},
	keywords = {HAR-smartphone},
	pages = {6},
	file = {Anguita et al. - 2013 - A Public Domain Dataset for Human Activity Recogni.pdf:/Users/gadmohamed/Zotero/storage/49QMASB3/Anguita et al. - 2013 - A Public Domain Dataset for Human Activity Recogni.pdf:application/pdf},
}

@article{gadFederatedLearningAugmented2023,
	title = {Federated {Learning} via {Augmented} {Knowledge} {Distillation} for {Heterogenous} {Deep} {Human} {Activity} {Recognition} {Systems}},
	volume = {23},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/1/6},
	doi = {10.3390/s23010006},
	abstract = {Deep learning-based Human Activity Recognition (HAR) systems received a lot of interest for health monitoring and activity tracking on wearable devices. The availability of large and representative datasets is often a requirement for training accurate deep learning models. To keep private data on users\&rsquo; devices while utilizing them to train deep learning models on huge datasets, Federated Learning (FL) was introduced as an inherently private distributed training paradigm. However, standard FL (FedAvg) lacks the capability to train heterogeneous model architectures. In this paper, we propose Federated Learning via Augmented Knowledge Distillation (FedAKD) for distributed training of heterogeneous models. FedAKD is evaluated on two HAR datasets: A waist-mounted tabular HAR dataset and a wrist-mounted time-series HAR dataset. FedAKD is more flexible than standard federated learning (FedAvg) as it enables collaborative heterogeneous deep learning models with various learning capacities. In the considered FL experiments, the communication overhead under FedAKD is 200X less compared with FL methods that communicate models\&rsquo; gradients/weights. Relative to other model-agnostic FL methods, results show that FedAKD boosts performance gains of clients by up to 20 percent. Furthermore, FedAKD is shown to be relatively more robust under statistical heterogeneous scenarios.},
	number = {1},
	journal = {Sensors},
	author = {Gad, Gad and Fadlullah, Zubair},
	year = {2023},
	keywords = {federated learning, Internet of Things, deep learning, human activity recognition, hyperparameter tuning, knowledge distillation},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/8C8D28PM/Gad and Fadlullah - 2023 - Federated Learning via Augmented Knowledge Distill.pdf:application/pdf},
}

@misc{liFederatedOptimizationHeterogeneous2020,
	title = {Federated {Optimization} in {Heterogeneous} {Networks}},
	url = {http://arxiv.org/abs/1812.06127},
	doi = {10.48550/arXiv.1812.06127},
	abstract = {Federated Learning is a distributed learning paradigm with two key challenges that differentiate it from traditional distributed optimization: (1) significant variability in terms of the systems characteristics on each device in the network (systems heterogeneity), and (2) non-identically distributed data across the network (statistical heterogeneity). In this work, we introduce a framework, FedProx, to tackle heterogeneity in federated networks. FedProx can be viewed as a generalization and re-parametrization of FedAvg, the current state-of-the-art method for federated learning. While this re-parameterization makes only minor modifications to the method itself, these modifications have important ramifications both in theory and in practice. Theoretically, we provide convergence guarantees for our framework when learning over data from non-identical distributions (statistical heterogeneity), and while adhering to device-level systems constraints by allowing each participating device to perform a variable amount of work (systems heterogeneity). Practically, we demonstrate that FedProx allows for more robust convergence than FedAvg across a suite of realistic federated datasets. In particular, in highly heterogeneous settings, FedProx demonstrates significantly more stable and accurate convergence behavior relative to FedAvg---improving absolute test accuracy by 22\% on average.},
	urldate = {2023-03-07},
	publisher = {arXiv},
	author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
	month = apr,
	year = {2020},
	note = {arXiv:1812.06127 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: MLSys 2020},
	file = {arXiv Fulltext PDF:/Users/gadmohamed/Zotero/storage/DU8USGCS/Li et al. - 2020 - Federated Optimization in Heterogeneous Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/gadmohamed/Zotero/storage/BKCZ48ZQ/1812.html:text/html},
}

@misc{OneFiveAmericans2020,
	title = {One in five {Americans} now wear a smartwatch or fitness tracker},
	url = {https://www.techspot.com/news/83487-one-five-americans-now-wear-smartwatch-or-fitness.html},
	abstract = {The information comes from a Pew Research Center study, which shows that, as with most tech, wearables adoption is higher (31 percent) in households earning \$75,000 or...},
	language = {en-US},
	urldate = {2023-03-07},
	journal = {TechSpot},
	month = jan,
	year = {2020},
	file = {Snapshot:/Users/gadmohamed/Zotero/storage/B88F9MHD/83487-one-five-americans-now-wear-smartwatch-or-fitness.html:text/html},
}

@article{liFederatedOptimizationHeterogeneous2020a,
	title = {Federated {Optimization} in {Heterogeneous} {Networks}},
	volume = {2},
	url = {https://proceedings.mlsys.org/paper/2020/hash/38af86134b65d0f10fe33d30dd76442e-Abstract.html},
	language = {en},
	urldate = {2023-03-07},
	journal = {Proceedings of Machine Learning and Systems},
	author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
	month = mar,
	year = {2020},
	pages = {429--450},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/AM98IJZA/Li et al. - 2020 - Federated Optimization in Heterogeneous Networks.pdf:application/pdf},
}

@inproceedings{liFederatedOptimizationHeterogeneous2020b,
	title = {Federated {Optimization} in {Heterogeneous} {Networks}},
	volume = {2},
	url = {https://proceedings.mlsys.org/paper/2020/file/38af86134b65d0f10fe33d30dd76442e-Paper.pdf},
	booktitle = {Proceedings of {Machine} {Learning} and {Systems}},
	author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
	editor = {Dhillon, I. and Papailiopoulos, D. and Sze, V.},
	year = {2020},
	pages = {429--450},
}

@inproceedings{liFederatedOptimizationHeterogeneous2020c,
	title = {Federated {Optimization} in {Heterogeneous} {Networks}},
	volume = {2},
	url = {https://proceedings.mlsys.org/paper/2020/file/38af86134b65d0f10fe33d30dd76442e-Paper.pdf},
	booktitle = {Proceedings of {Machine} {Learning} and {Systems}},
	author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
	editor = {Dhillon, I. and Papailiopoulos, D. and Sze, V.},
	year = {2020},
	pages = {429--450},
}

@article{dworkAlgorithmicFoundationsDifferential2013,
	title = {The {Algorithmic} {Foundations} of {Differential} {Privacy}},
	volume = {9},
	issn = {1551-305X},
	url = {https://dx.doi.org/10.1561/0400000042},
	doi = {10.1561/0400000042},
	number = {3-4},
	journal = {Foundations and Trends® in Theoretical Computer Science},
	author = {Dwork, Cynthia and Roth, Aaron},
	year = {2013},
	note = {Publisher: Now Publishers},
	pages = {211--407},
}

@article{weiFederatedLearningDifferential2020,
	title = {Federated {Learning} {With} {Differential} {Privacy}: {Algorithms} and {Performance} {Analysis}},
	volume = {15},
	issn = {1556-6021},
	shorttitle = {Federated {Learning} {With} {Differential} {Privacy}},
	doi = {10.1109/TIFS.2020.2988575},
	abstract = {Federated learning (FL), as a type of distributed machine learning, is capable of significantly preserving clients’ private data from being exposed to adversaries. Nevertheless, private information can still be divulged by analyzing uploaded parameters from clients, e.g., weights trained in deep neural networks. In this paper, to effectively prevent information leakage, we propose a novel framework based on the concept of differential privacy (DP), in which artificial noise is added to parameters at the clients’ side before aggregating, namely, noising before model aggregation FL (NbAFL). First, we prove that the NbAFL can satisfy DP under distinct protection levels by properly adapting different variances of artificial noise. Then we develop a theoretical convergence bound on the loss function of the trained FL model in the NbAFL. Specifically, the theoretical bound reveals the following three key properties: 1) there is a tradeoff between convergence performance and privacy protection levels, i.e., better convergence performance leads to a lower protection level; 2) given a fixed privacy protection level, increasing the number \$N\$ of overall clients participating in FL can improve the convergence performance; and 3) there is an optimal number aggregation times (communication rounds) in terms of convergence performance for a given protection level. Furthermore, we propose a \$K\$ -client random scheduling strategy, where \$K\$ ( \$1{\textbackslash}leq K{\textless} N\$ ) clients are randomly selected from the \$N\$ overall clients to participate in each aggregation. We also develop a corresponding convergence bound for the loss function in this case and the \$K\$ -client random scheduling strategy also retains the above three properties. Moreover, we find that there is an optimal \$K\$ that achieves the best convergence performance at a fixed privacy level. Evaluations demonstrate that our theoretical results are consistent with simulations, thereby facilitating the design of various privacy-preserving FL algorithms with different tradeoff requirements on convergence performance and privacy levels.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Wei, Kang and Li, Jun and Ding, Ming and Ma, Chuan and Yang, Howard H. and Farokhi, Farhad and Jin, Shi and Quek, Tony Q. S. and Vincent Poor, H.},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Servers, client selection, Convergence, Training, Analytical models, convergence performance, differential privacy, Distributed databases, Federated learning, information leakage, Privacy},
	pages = {3454--3469},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/AZR4JZGS/9069945.html:text/html;IEEE Xplore Full Text PDF:/Users/gadmohamed/Zotero/storage/9LLDCJ5Y/Wei et al. - 2020 - Federated Learning With Differential Privacy Algo.pdf:application/pdf},
}

@article{UnknownArticle,
	title = {Unknown article},
	url = {https://dx.doi.org/10.48550/arxiv.2009.05537},
	doi = {10.48550/arxiv.2009.05537},
	file = {Full Text:/Users/gadmohamed/Zotero/storage/CRICUWAJ/Unknown article.pdf:application/pdf},
}

@inproceedings{sunFederatedModelDistillation2021,
	title = {Federated {Model} {Distillation} with {Noise}-{Free} {Differential} {Privacy}},
	volume = {2},
	url = {https://www.ijcai.org/proceedings/2021/216},
	doi = {10.24963/ijcai.2021/216},
	abstract = {Electronic proceedings of IJCAI 2021},
	language = {en},
	urldate = {2023-03-07},
	author = {Sun, Lichao and Lyu, Lingjuan},
	month = aug,
	year = {2021},
	note = {ISSN: 1045-0823},
	pages = {1563--1570},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/BQ8TUTU2/Sun and Lyu - 2021 - Federated Model Distillation with Noise-Free Diffe.pdf:application/pdf},
}

@misc{liFedMDHeterogenousFederated2019,
	title = {{FedMD}: {Heterogenous} {Federated} {Learning} via {Model} {Distillation}},
	shorttitle = {{FedMD}},
	url = {http://arxiv.org/abs/1910.03581},
	abstract = {Federated learning enables the creation of a powerful centralized model without compromising data privacy of multiple participants. While successful, it does not incorporate the case where each participant independently designs its own model. Due to intellectual property concerns and heterogeneous nature of tasks and data, this is a widespread requirement in applications of federated learning to areas such as health care and AI as a service. In this work, we use transfer learning and knowledge distillation to develop a universal framework that enables federated learning when each agent owns not only their private data, but also uniquely designed models. We test our framework on the MNIST/FEMNIST dataset and the CIFAR10/CIFAR100 dataset and observe fast improvement across all participating models. With 10 distinct participants, the final test accuracy of each model on average receives a 20\% gain on top of what's possible without collaboration and is only a few percent lower than the performance each model would have obtained if all private datasets were pooled and made directly available for all participants.},
	urldate = {2023-03-07},
	publisher = {arXiv},
	author = {Li, Daliang and Wang, Junpu},
	month = oct,
	year = {2019},
	note = {arXiv:1910.03581 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 4 pages, 2 figures, NeurIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality},
	file = {arXiv Fulltext PDF:/Users/gadmohamed/Zotero/storage/3RUMEEDH/Li and Wang - 2019 - FedMD Heterogenous Federated Learning via Model D.pdf:application/pdf;arXiv.org Snapshot:/Users/gadmohamed/Zotero/storage/KC6RLLZL/1910.html:text/html},
}

@article{demrozi2020human,
	title = {Human activity recognition using inertial, physiological and environmental sensors: {A} comprehensive survey},
	volume = {8},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Demrozi, Florenc and Pravadelli, Graziano and Bihorac, Azra and Rashidi, Parisa},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {210816--210836},
}

@inproceedings{chung2018sensor,
	title = {Sensor positioning and data acquisition for activity recognition using deep learning},
	booktitle = {2018 international conference on information and communication technology convergence ({ICTC})},
	author = {Chung, Seungeun and Lim, Jiyoun and Noh, Kyoung Ju and Kim, Ga Gue and Jeong, Hyun Tae},
	year = {2018},
	note = {tex.organization: IEEE},
	pages = {154--159},
}

@article{jobanputra2019human,
	title = {Human activity recognition: {A} survey},
	volume = {155},
	journal = {Procedia Computer Science},
	author = {Jobanputra, Charmi and Bavishi, Jatna and Doshi, Nishant},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {698--703},
}

@inproceedings{anguita2012human,
	title = {Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine},
	booktitle = {International workshop on ambient assisted living},
	author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier and Reyes-Ortiz, Jorge L},
	year = {2012},
	note = {tex.organization: Springer},
	pages = {216--223},
}

@article{kaghyan2012activity,
	title = {Activity recognition using k-nearest neighbor algorithm on smartphone with tri-axial accelerometer},
	volume = {1},
	journal = {International Journal of Informatics Models and Analysis (IJIMA), ITHEA International Scientific Society, Bulgaria},
	author = {Kaghyan, Sahak and Sarukhanyan, Hakob},
	year = {2012},
	pages = {146--156},
}

@inproceedings{sun2010activity,
	title = {Activity recognition on an accelerometer embedded mobile phone with varying positions and orientations},
	booktitle = {International conference on ubiquitous intelligence and computing},
	author = {Sun, Lin and Zhang, Daqing and Li, Bin and Guo, Bin and Li, Shijian},
	year = {2010},
	note = {tex.organization: Springer},
	pages = {548--562},
}

@article{tekler2020near,
	title = {Near-real-time plug load identification using low-frequency power data in office spaces: {Experiments} and applications},
	volume = {275},
	journal = {Applied Energy},
	author = {Tekler, Zeynep Duygu and Low, Raymond and Zhou, Yuren and Yuen, Chau and Blessing, Lucienne and Spanos, Costas},
	year = {2020},
	note = {Publisher: Elsevier},
	pages = {115391},
}

@article{low2020commercial,
	title = {Commercial vehicle activity prediction with imbalanced class distribution using a hybrid sampling and gradient boosting approach},
	volume = {22},
	number = {3},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Low, Raymond and Cheah, Lynette and You, Linlin},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {1401--1410},
}

@misc{WinNT,
	title = {About one-in-five {Americans} use a smart watch or fitness tracker},
	url = {https://www.pewresearch.org/fact-tank/2020/01/09/about-one-in-five-americans-use-a-smart-watch-or-fitness-tracker/},
	annote = {Accessed: 2022-10-22},
}

@article{aschbacher2020atrial,
	title = {Atrial fibrillation detection from raw photoplethysmography waveforms: {A} deep learning application},
	volume = {1},
	number = {1},
	journal = {Heart rhythm O2},
	author = {Aschbacher, Kirstin and Yilmaz, Defne and Kerem, Yaniv and Crawford, Stuart and Benaron, David and Liu, Jiaqi and Eaton, Meghan and Tison, Geoffrey H and Olgin, Jeffrey E and Li, Yihan and {others}},
	year = {2020},
	note = {Publisher: Elsevier},
	pages = {3--9},
}

@article{boukhechba2019actippg,
	title = {{ActiPPG}: using deep neural networks for activity recognition from wrist-worn photoplethysmography ({PPG}) sensors},
	volume = {14},
	journal = {Smart Health},
	author = {Boukhechba, Mehdi and Cai, Lihua and Wu, Congyu and Barnes, Laura E},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {100082},
}

@incollection{mekruksavanich2022cnn,
	title = {{CNN}-{Based} deep learning network for human activity recognition during physical exercise from accelerometer and photoplethysmographic sensors},
	booktitle = {Computer networks, big data and {IoT}},
	publisher = {Springer},
	author = {Mekruksavanich, Sakorn and Jitpattanakul, Anuchit},
	year = {2022},
	pages = {531--542},
}

@inproceedings{bhat2018online,
	title = {Online human activity recognition using low-power wearable devices},
	booktitle = {2018 {IEEE}/{ACM} international conference on computer-aided design ({ICCAD})},
	author = {Bhat, Ganapati and Deb, Ranadeep and Chaurasia, Vatika Vardhan and Shill, Holly and Ogras, Umit Y},
	year = {2018},
	note = {tex.organization: IEEE},
	pages = {1--8},
}

@inproceedings{zeng2018understanding,
	title = {Understanding and improving recurrent networks for human activity recognition by continuous attention},
	booktitle = {Proceedings of the 2018 {ACM} international symposium on wearable computers},
	author = {Zeng, Ming and Gao, Haoxiang and Yu, Tong and Mengshoel, Ole J and Langseth, Helge and Lane, Ian and Liu, Xiaobing},
	year = {2018},
	pages = {56--63},
}

@article{zhang2018mixup,
	title = {mixup: {Beyond} empirical risk minimization},
	url = {https://openreview.net/forum?id=r1Ddp1-Rb},
	journal = {International Conference on Learning Representations},
	author = {Hongyi Zhang, Moustapha Cisse, David Lopez-Paz, Yann N. Dauphin},
	year = {2018},
}

@inproceedings{anguita2013public,
	title = {A public domain dataset for human activity recognition using smartphones},
	booktitle = {Proceedings of the 21th international {European} symposium on artificial neural networks, computational intelligence and machine learning},
	author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra Perez, Xavier and Reyes Ortiz, Jorge Luis},
	year = {2013},
	pages = {437--442},
}

@article{elmenreich2002introduction,
	title = {An introduction to sensor fusion},
	volume = {502},
	journal = {Vienna University of Technology, Austria},
	author = {Elmenreich, Wilfried},
	year = {2002},
	pages = {1--28},
}

@inproceedings{laidig2017exploiting,
	title = {Exploiting kinematic constraints to compensate magnetic disturbances when calculating joint angles of approximate hinge joints from orientation estimates of inertial sensors},
	booktitle = {2017 international conference on rehabilitation robotics ({ICORR})},
	author = {Laidig, Daniel and Schauer, Thomas and Seel, Thomas},
	year = {2017},
	note = {tex.organization: IEEE},
	pages = {971--976},
}

@article{zampieri2010instrumented,
	title = {The instrumented timed up and go test: potential outcome measure for disease modifying therapies in {Parkinson}'s disease},
	volume = {81},
	number = {2},
	journal = {Journal of Neurology, Neurosurgery \& Psychiatry},
	author = {Zampieri, Cris and Salarian, Arash and Carlson-Kuhta, Patricia and Aminian, Kamiar and Nutt, John G and Horak, Fay B},
	year = {2010},
	note = {Publisher: BMJ Publishing Group Ltd},
	pages = {171--176},
}

@article{diaz2019use,
	title = {Use of wearable sensor technology in gait, balance, and range of motion analysis},
	volume = {10},
	number = {1},
	journal = {Applied Sciences},
	author = {Díaz, Steven and Stephenson, Jeannie B and Labrador, Miguel A},
	year = {2019},
	note = {Publisher: MDPI},
	pages = {234},
}

@article{bhattacharya2022ensem,
	title = {Ensem-{HAR}: {An} ensemble deep learning model for smartphone sensor-based human activity recognition for measurement of elderly health monitoring},
	volume = {12},
	number = {6},
	journal = {Biosensors},
	author = {Bhattacharya, Debarshi and Sharma, Deepak and Kim, Wonjoon and Ijaz, Muhammad Fazal and Singh, Pawan Kumar},
	year = {2022},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {393},
}

@article{parkka2006activity,
	title = {Activity classification using realistic data from wearable sensors},
	volume = {10},
	number = {1},
	journal = {IEEE Transactions on information technology in biomedicine},
	author = {Parkka, Juha and Ermes, Miikka and Korpipaa, Panu and Mantyjarvi, Jani and Peltola, Johannes and Korhonen, Ilkka},
	year = {2006},
	note = {Publisher: IEEE},
	pages = {119--128},
}

@inproceedings{tapia2007real,
	title = {Real-time recognition of physical activities and their intensities using wireless accelerometers and a heart rate monitor},
	booktitle = {2007 11th {IEEE} international symposium on wearable computers},
	author = {Tapia, Emmanuel Munguia and Intille, Stephen S and Haskell, William and Larson, Kent and Wright, Julie and King, Abby and Friedman, Robert},
	year = {2007},
	note = {tex.organization: IEEE},
	pages = {37--40},
}

@article{lara2012centinela,
	title = {Centinela: {A} human activity recognition system based on acceleration and vital sign data},
	volume = {8},
	number = {5},
	journal = {Pervasive and mobile computing},
	author = {Lara, Oscar D and Pérez, Alfredo J and Labrador, Miguel A and Posada, José D},
	year = {2012},
	note = {Publisher: Elsevier},
	pages = {717--729},
}

@inproceedings{bao2004activity,
	title = {Activity recognition from user-annotated acceleration data},
	booktitle = {International conference on pervasive computing},
	author = {Bao, Ling and Intille, Stephen S},
	year = {2004},
	note = {tex.organization: Springer},
	pages = {1--17},
}

@inproceedings{tu2021feddl,
	title = {Feddl: {Federated} learning via dynamic layer sharing for human activity recognition},
	booktitle = {Proceedings of the 19th {ACM} conference on embedded networked sensor systems},
	author = {Tu, Linlin and Ouyang, Xiaomin and Zhou, Jiayu and He, Yuze and Xing, Guoliang},
	year = {2021},
	pages = {15--28},
}

@inproceedings{sozinov2018human,
	title = {Human activity recognition using federated learning},
	booktitle = {2018 {IEEE} intl conf on parallel \& distributed processing with applications, ubiquitous computing \& communications, big data \& cloud computing, social computing \& networking, sustainable computing \& communications ({ISPA}/{IUCC}/{BDCloud}/{SocialCom}/{SustainCom})},
	author = {Sozinov, Konstantin and Vlassov, Vladimir and Girdzijauskas, Sarunas},
	year = {2018},
	note = {tex.organization: IEEE},
	pages = {1103--1111},
}

@article{savitzky1964smoothing,
	title = {Smoothing and differentiation of data by simplified least squares procedures.},
	volume = {36},
	number = {8},
	journal = {Analytical chemistry},
	author = {Savitzky, Abraham and Golay, Marcel JE},
	year = {1964},
	note = {Publisher: ACS Publications},
	pages = {1627--1639},
}

@inproceedings{buolamwini2018gender,
	title = {Gender shades: {Intersectional} accuracy disparities in commercial gender classification},
	booktitle = {Conference on fairness, accountability and transparency},
	author = {Buolamwini, Joy and Gebru, Timnit},
	year = {2018},
	note = {tex.organization: PMLR},
	pages = {77--91},
}

@article{graves2012long,
	title = {Long short-term memory},
	journal = {Supervised sequence labelling with recurrent neural networks},
	author = {Graves, Alex},
	year = {2012},
	note = {Publisher: Springer},
	pages = {37--45},
}

@inproceedings{kiranyaz20191,
	title = {1-{D} convolutional neural networks for signal processing applications},
	booktitle = {{ICASSP} 2019-2019 {IEEE} international conference on acoustics, speech and signal processing ({ICASSP})},
	author = {Kiranyaz, Serkan and Ince, Turker and Abdeljaber, Osama and Avci, Onur and Gabbouj, Moncef},
	year = {2019},
	note = {tex.organization: IEEE},
	pages = {8360--8364},
}

@article{baldi2013understanding,
	title = {Understanding dropout},
	volume = {26},
	journal = {Advances in neural information processing systems},
	author = {Baldi, Pierre and Sadowski, Peter J},
	year = {2013},
}

@inproceedings{lawrence2000overfitting,
	title = {Overfitting and neural networks: conjugate gradient and backpropagation},
	volume = {1},
	booktitle = {Proceedings of the {IEEE}-{INNS}-{ENNS} international joint conference on neural networks. {IJCNN} 2000. {Neural} computing: {New} challenges and perspectives for the new millennium},
	author = {Lawrence, Steve and Giles, C Lee},
	year = {2000},
	note = {tex.organization: IEEE},
	pages = {114--119},
}

@article{netrapalli2019stochastic,
	title = {Stochastic gradient descent and its variants in machine learning},
	volume = {99},
	number = {2},
	journal = {Journal of the Indian Institute of Science},
	author = {Netrapalli, Praneeth},
	year = {2019},
	note = {Publisher: Springer},
	pages = {201--213},
}

@inproceedings{zhang2018improved,
	title = {Improved adam optimizer for deep neural networks},
	booktitle = {2018 {IEEE}/{ACM} 26th international symposium on quality of service ({IWQoS})},
	author = {Zhang, Zijun},
	year = {2018},
	note = {tex.organization: Ieee},
	pages = {1--2},
}

@inproceedings{mukkamala2017variants,
	title = {Variants of rmsprop and adagrad with logarithmic regret bounds},
	booktitle = {International conference on machine learning},
	author = {Mukkamala, Mahesh Chandra and Hein, Matthias},
	year = {2017},
	note = {tex.organization: PMLR},
	pages = {2545--2553},
}

@article{ramasamy2022secure,
	title = {Secure smart wearable computing through artificial intelligence-enabled internet of things and cyber-physical systems for health monitoring},
	volume = {22},
	number = {3},
	journal = {Sensors},
	author = {Ramasamy, Lakshmana Kumar and Khan, Firoz and Shah, Mohammad and Prasad, Balusupati Veera Venkata Siva and Iwendi, Celestine and Biamba, Cresantus},
	year = {2022},
	note = {Publisher: MDPI},
	pages = {1076},
}

@incollection{hecht1992theory,
	title = {Theory of the backpropagation neural network},
	booktitle = {Neural networks for perception},
	publisher = {Elsevier},
	author = {Hecht-Nielsen, Robert},
	year = {1992},
	pages = {65--93},
}

@incollection{goyal2020activation,
	title = {Activation functions},
	booktitle = {Deep learning: {Algorithms} and applications},
	publisher = {Springer},
	author = {Goyal, Mohit and Goyal, Rajan and Venkatappa Reddy, P and Lall, Brejesh},
	year = {2020},
	pages = {1--30},
}

@article{apicella2021survey,
	title = {A survey on modern trainable activation functions},
	volume = {138},
	journal = {Neural Networks},
	author = {Apicella, Andrea and Donnarumma, Francesco and Isgrò, Francesco and Prevete, Roberto},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {14--32},
}

@article{bulling2014tutorial,
	title = {A tutorial on human activity recognition using body-worn inertial sensors},
	volume = {46},
	number = {3},
	journal = {ACM Computing Surveys (CSUR)},
	author = {Bulling, Andreas and Blanke, Ulf and Schiele, Bernt},
	year = {2014},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--33},
}

@article{lara2012survey,
	title = {A survey on human activity recognition using wearable sensors},
	volume = {15},
	number = {3},
	journal = {IEEE communications surveys \& tutorials},
	author = {Lara, Oscar D and Labrador, Miguel A},
	year = {2012},
	note = {Publisher: IEEE},
	pages = {1192--1209},
}

@article{tekler2022occupancy,
	title = {Occupancy prediction using deep learning approaches across multiple space types: {A} minimum sensing strategy},
	volume = {226},
	journal = {Building and Environment},
	author = {Tekler, Zeynep Duygu and Chong, Adrian},
	year = {2022},
	note = {Publisher: Elsevier},
	pages = {109689},
}

@article{kulsoom2022review,
	title = {A review of machine learning-based human activity recognition for diverse applications},
	journal = {Neural Computing and Applications},
	author = {Kulsoom, Farzana and Narejo, Sanam and Mehmood, Zahid and Chaudhry, Hassan Nazeer and Bashir, Ali Kashif and {others}},
	year = {2022},
	note = {Publisher: Springer},
	pages = {1--36},
}

@article{zhang2022deep,
	title = {Deep learning in human activity recognition with wearable sensors: {A} review on advances},
	volume = {22},
	number = {4},
	journal = {Sensors},
	author = {Zhang, Shibo and Li, Yaxuan and Zhang, Shen and Shahabi, Farzad and Xia, Stephen and Deng, Yu and Alshurafa, Nabil},
	year = {2022},
	note = {Publisher: MDPI},
	pages = {1476},
}

@article{zhang2022if,
	title = {{IF}-{ConvTransformer}: {A} framework for human activity recognition using {IMU} fusion and {ConvTransformer}},
	volume = {6},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Zhang, Ye and Wang, Longguang and Chen, Huiling and Tian, Aosheng and Zhou, Shilin and Guo, Yulan},
	year = {2022},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--26},
}

@article{li2022human,
	title = {Human activity recognition based on residual network and {BiLSTM}},
	volume = {22},
	number = {2},
	journal = {Sensors},
	author = {Li, Yong and Wang, Luping},
	year = {2022},
	note = {Publisher: MDPI},
	pages = {635},
}

@article{chen2021deep,
	title = {Deep learning for sensor-based human activity recognition: {Overview}, challenges, and opportunities},
	volume = {54},
	number = {4},
	journal = {ACM Computing Surveys (CSUR)},
	author = {Chen, Kaixuan and Zhang, Dalin and Yao, Lina and Guo, Bin and Yu, Zhiwen and Liu, Yunhao},
	year = {2021},
	note = {Publisher: ACM New York, NY, USA},
	pages = {1--40},
}

@article{ouyang2022clusterfl,
	title = {{ClusterFL}: {A} clustering-based federated learning system for human activity recognition},
	journal = {ACM Transactions on Sensor Networks (TOSN)},
	author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Xing, Guoliang and Huang, Jianwei},
	year = {2022},
	note = {Publisher: ACM New York, NY},
}

@article{xiao2021federated,
	title = {A federated learning system with enhanced feature extraction for human activity recognition},
	volume = {229},
	journal = {Knowledge-Based Systems},
	author = {Xiao, Zhiwen and Xu, Xin and Xing, Huanlai and Song, Fuhong and Wang, Xinhan and Zhao, Bowen},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {107338},
}

@inproceedings{doshi2022federated,
	title = {Federated learning-based driver activity recognition for edge devices},
	booktitle = {Proceedings of the {IEEE}/{CVF} conference on computer vision and pattern recognition},
	author = {Doshi, Keval and Yilmaz, Yasin},
	year = {2022},
	pages = {3338--3346},
}

@article{wood2022deep,
	title = {Deep learning to automate the labelling of head {MRI} datasets for computer vision applications},
	volume = {32},
	number = {1},
	journal = {European Radiology},
	author = {Wood, David A and Kafiabadi, Sina and Al Busaidi, Aisha and Guilhem, Emily L and Lynch, Jeremy and Townend, Matthew K and Montvila, Antanas and Kiik, Martin and Siddiqui, Juveria and Gadapa, Naveen and {others}},
	year = {2022},
	note = {Publisher: Springer},
	pages = {725--736},
}

@inproceedings{schafer2006recurrent,
	title = {Recurrent neural networks are universal approximators},
	booktitle = {International conference on artificial neural networks},
	author = {Schäfer, Anton Maximilian and Zimmermann, Hans Georg},
	year = {2006},
	note = {tex.organization: Springer},
	pages = {632--640},
}

@article{zhou2020universality,
	title = {Universality of deep convolutional neural networks},
	volume = {48},
	number = {2},
	journal = {Applied and computational harmonic analysis},
	author = {Zhou, Ding-Xuan},
	year = {2020},
	note = {Publisher: Elsevier},
	pages = {787--794},
}

@article{bjerge2022real,
	title = {Real-time insect tracking and monitoring with computer vision and deep learning},
	volume = {8},
	number = {3},
	journal = {Remote Sensing in Ecology and Conservation},
	author = {Bjerge, Kim and Mann, Hjalte MR and Høye, Toke Thomas},
	year = {2022},
	note = {Publisher: Wiley Online Library},
	pages = {315--327},
}

@article{bouguettaya2022review,
	title = {A review on early wildfire detection from unmanned aerial vehicles using deep learning-based computer vision algorithms},
	volume = {190},
	journal = {Signal Processing},
	author = {Bouguettaya, Abdelmalek and Zarzour, Hafed and Taberkit, Amine Mohammed and Kechida, Ahmed},
	year = {2022},
	note = {Publisher: Elsevier},
	pages = {108309},
}

@article{lauriola2022introduction,
	title = {An introduction to deep learning in natural language processing: {Models}, techniques, and tools},
	volume = {470},
	journal = {Neurocomputing},
	author = {Lauriola, Ivano and Lavelli, Alberto and Aiolli, Fabio},
	year = {2022},
	note = {Publisher: Elsevier},
	pages = {443--456},
}

@article{yang2019federated,
	title = {Federated learning},
	volume = {13},
	number = {3},
	journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	author = {Yang, Qiang and Liu, Yang and Cheng, Yong and Kang, Yan and Chen, Tianjian and Yu, Han},
	year = {2019},
	note = {Publisher: Morgan \& Claypool Publishers},
	pages = {1--207},
}

@inproceedings{li2021model,
	title = {Model-contrastive federated learning},
	booktitle = {Proceedings of the {IEEE}/{CVF} conference on computer vision and pattern recognition},
	author = {Li, Qinbin and He, Bingsheng and Song, Dawn},
	year = {2021},
	pages = {10713--10722},
}

@article{gou2021knowledge,
	title = {Knowledge distillation: {A} survey},
	volume = {129},
	number = {6},
	journal = {International Journal of Computer Vision},
	author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
	year = {2021},
	note = {Publisher: Springer},
	pages = {1789--1819},
}

@article{diao2020heterofl,
	title = {{HeteroFL}: {Computation} and communication efficient federated learning for heterogeneous clients},
	journal = {arXiv preprint arXiv:2010.01264},
	author = {Diao, Enmao and Ding, Jie and Tarokh, Vahid},
	year = {2020},
}

@inproceedings{zhu2021data,
	title = {Data-free knowledge distillation for heterogeneous federated learning},
	booktitle = {International conference on machine learning},
	author = {Zhu, Zhuangdi and Hong, Junyuan and Zhou, Jiayu},
	year = {2021},
	note = {tex.organization: PMLR},
	pages = {12878--12889},
}

@inproceedings{lin2018dgc,
	title = {Deep {Gradient} {Compression}: {Reducing} the communication bandwidth for distributed training},
	booktitle = {The international conference on learning representations},
	author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J},
	year = {2018},
}

@article{wuSAFASemiAsynchronousProtocol2021,
	title = {{SAFA}: {A} {Semi}-{Asynchronous} {Protocol} for {Fast} {Federated} {Learning} {With} {Low} {Overhead}},
	volume = {70},
	issn = {1557-9956},
	shorttitle = {{SAFA}},
	doi = {10.1109/TC.2020.2994391},
	abstract = {Federated learning (FL) has attracted increasing attention as a promising approach to driving a vast number of end devices with artificial intelligence. However, it is very challenging to guarantee the efficiency of FL considering the unreliable nature of end devices while the cost of device-server communication cannot be neglected. In this article, we propose SAFA, a semi-asynchronous FL protocol, to address the problems in federated learning such as low round efficiency and poor convergence rate in extreme conditions (e.g., clients dropping offline frequently). We introduce novel designs in the steps of model distribution, client selection and global aggregation to mitigate the impacts of stragglers, crashes and model staleness in order to boost efficiency and improve the quality of the global model. We have conducted extensive experiments with typical machine learning tasks. The results demonstrate that the proposed protocol is effective in terms of shortening federated round duration, reducing local resource wastage, and improving the accuracy of the global model at an acceptable communication cost.},
	number = {5},
	journal = {IEEE Transactions on Computers},
	author = {Wu, Wentai and He, Ligang and Lin, Weiwei and Mao, Rui and Maple, Carsten and Jarvis, Stephen},
	month = may,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Computers},
	keywords = {Machine learning, Data models, federated learning, Convergence, Training, Distributed databases, Distributed computing, edge intelligence, machine learning, Optimization, Protocols},
	pages = {655--668},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/BTPGHQFG/9093123.html:text/html;Submitted Version:/Users/gadmohamed/Zotero/storage/UFWJ4RW4/Wu et al. - 2021 - SAFA A Semi-Asynchronous Protocol for Fast Federa.pdf:application/pdf},
}

@article{liFederatedLearningChallenges2020,
	title = {Federated {Learning}: {Challenges}, {Methods}, and {Future} {Directions}},
	volume = {37},
	issn = {1558-0792},
	shorttitle = {Federated {Learning}},
	doi = {10.1109/MSP.2020.2975749},
	abstract = {Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.},
	number = {3},
	journal = {IEEE Signal Processing Magazine},
	author = {Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
	month = may,
	year = {2020},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Machine learning, Data models, Data privacy, Distributed databases, Privacy, Predictive models, Training data},
	pages = {50--60},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/L4P2PARF/9084352.html:text/html;Submitted Version:/Users/gadmohamed/Zotero/storage/XG8MA3ZG/Li et al. - 2020 - Federated Learning Challenges, Methods, and Futur.pdf:application/pdf},
}

@inproceedings{geipingInvertingGradientsHow2020,
	title = {Inverting {Gradients} - {How} easy is it to break privacy in federated learning?},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/c4ede56bbd98819ae6112b20ac6bf145-Abstract.html},
	abstract = {The idea of federated learning is to collaboratively train a neural network on a server. Each user receives the current weights of the network and in turns sends parameter updates (gradients) based on local data. This protocol has been designed not only to train neural networks data-efficiently, but also to provide privacy benefits for users, as their input data remains on device and only parameter gradients are shared. 
But how secure is sharing parameter gradients? Previous attacks have provided a false sense of security, by succeeding only in contrived settings - even for a single image. However, by exploiting a magnitude-invariant loss along with optimization strategies based on adversarial attacks, we show that is is actually possible to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks.
We analyze the effects of architecture as well as parameters on the difficulty of reconstructing an input image and prove that any input to a fully connected layer can be reconstructed analytically independent of the remaining architecture. Finally we discuss settings encountered in practice and show that even averaging gradients over several iterations or several images does not protect the user's privacy in federated learning applications.},
	urldate = {2023-03-08},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Geiping, Jonas and Bauermeister, Hartmut and Dröge, Hannah and Moeller, Michael},
	year = {2020},
	pages = {16937--16947},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/ITXS8VLH/Geiping et al. - 2020 - Inverting Gradients - How easy is it to break priv.pdf:application/pdf},
}

@misc{chenPropSegmEntLargeScaleCorpus2022,
	title = {{PropSegmEnt}: {A} {Large}-{Scale} {Corpus} for {Proposition}-{Level} {Segmentation} and {Entailment} {Recognition}},
	shorttitle = {{PropSegmEnt}},
	url = {http://arxiv.org/abs/2212.10750},
	abstract = {The widely studied task of Natural Language Inference (NLI) requires a system to recognize whether one piece of text is textually entailed by another, i.e. whether the entirety of its meaning can be inferred from the other. In current NLI datasets and models, textual entailment relations are typically defined on the sentence- or paragraph-level. However, even a simple sentence often contains multiple propositions, i.e. distinct units of meaning conveyed by the sentence. As these propositions can carry different truth values in the context of a given premise, we argue for the need to recognize the textual entailment relation of each proposition in a sentence individually. We propose PropSegmEnt, a corpus of over 35K propositions annotated by expert human raters. Our dataset structure resembles the tasks of (1) segmenting sentences within a document to the set of propositions, and (2) classifying the entailment relation of each proposition with respect to a different yet topically-aligned document, i.e. documents describing the same event or entity. We establish strong baselines for the segmentation and entailment tasks. Through case studies on summary hallucination detection and document-level NLI, we demonstrate that our conceptual framework is potentially useful for understanding and explaining the compositionality of NLI labels.},
	urldate = {2023-03-08},
	publisher = {arXiv},
	author = {Chen, Sihao and Buthpitiya, Senaka and Fabrikant, Alex and Roth, Dan and Schuster, Tal},
	month = dec,
	year = {2022},
	note = {arXiv:2212.10750 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/gadmohamed/Zotero/storage/Q5P3GEW2/Chen et al. - 2022 - PropSegmEnt A Large-Scale Corpus for Proposition-.pdf:application/pdf;arXiv.org Snapshot:/Users/gadmohamed/Zotero/storage/4ZRRILFR/2212.html:text/html},
}

@inproceedings{williamsBroadCoverageChallengeCorpus2018,
	address = {New Orleans, Louisiana},
	title = {A {Broad}-{Coverage} {Challenge} {Corpus} for {Sentence} {Understanding} through {Inference}},
	url = {https://aclanthology.org/N18-1101},
	doi = {10.18653/v1/N18-1101},
	abstract = {This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.},
	urldate = {2023-03-08},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Williams, Adina and Nangia, Nikita and Bowman, Samuel},
	month = jun,
	year = {2018},
	pages = {1112--1122},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/KL5PYLDJ/Williams et al. - 2018 - A Broad-Coverage Challenge Corpus for Sentence Und.pdf:application/pdf},
}

@article{kim2021comparing,
	title = {Comparing kullback-leibler divergence and mean squared error loss in knowledge distillation},
	journal = {arXiv preprint arXiv:2105.08919},
	author = {Kim, Taehyeon and Oh, Jaehoon and Kim, NakYil and Cho, Sangwook and Yun, Se-Young},
	year = {2021},
}

@article{li2019fedmd,
	title = {{FedMD}: {Heterogenous} federated learning via model distillation},
	journal = {arXiv preprint arXiv:1910.03581},
	author = {Li, Daliang and Wang, Junpu},
	year = {2019},
}

@article{zhang2017mixup,
	title = {mixup: {Beyond} empirical risk minimization},
	journal = {arXiv preprint arXiv:1710.09412},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
	year = {2017},
}

@inproceedings{lin2008human,
	title = {Human activity recognition for video surveillance},
	booktitle = {2008 {IEEE} international symposium on circuits and systems ({ISCAS})},
	author = {Lin, Weiyao and Sun, Ming-Ting and Poovandran, Radha and Zhang, Zhengyou},
	year = {2008},
	note = {tex.organization: IEEE},
	pages = {2737--2740},
}

@article{wang2019survey,
	title = {A survey on wearable sensor modality centred human activity recognition in health care},
	volume = {137},
	journal = {Expert Systems with Applications},
	author = {Wang, Yan and Cang, Shuang and Yu, Hongnian},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {167--190},
}

@inproceedings{ogbuabor2018human,
	title = {Human activity recognition for healthcare using smartphones},
	booktitle = {Proceedings of the 2018 10th international conference on machine learning and computing},
	author = {Ogbuabor, Godwin and La, Robert},
	year = {2018},
	pages = {41--46},
}

@inproceedings{das2016real,
	title = {Real time heart rate detection from {PPG} signal in noisy environment},
	booktitle = {2016 international conference on intelligent control power and instrumentation ({ICICPI})},
	author = {Das, Sangita and Pal, Saurabh and Mitra, Madhuchhanda},
	year = {2016},
	note = {tex.organization: IEEE},
	pages = {70--73},
}

@article{bhattaraireview,
	title = {A review on human activity recognition techniques and comparative performance analysis},
	volume = {12},
	number = {1},
	journal = {World Journal of Innovative Research (WJIR)},
	author = {Bhattarai, Rohini and Bohara, Vipra},
	year = {2022},
	pages = {37--39},
}

@article{tang2022using,
	title = {Using a selective ensemble support vector machine to fuse multimodal features for human action recognition},
	volume = {2022, article no. 1877464},
	journal = {Computational Intelligence and Neuroscience},
	author = {Tang, Chao and Tong, Anyang and Zheng, Aihua and Peng, Hua and Li, Wei},
	year = {2022},
	note = {Publisher: Hindawi},
}

@inproceedings{al2021optimizing,
	title = {Optimizing the performance of {KNN} classifier for human activity recognition},
	booktitle = {International conference on advances in computing and data sciences},
	author = {Al-Taei, Ali and Ibrahim, Mohammed Fadhil and Habeeb, Nada Jasim},
	year = {2021},
	pages = {373--385},
}

@article{liu2021efficient,
	title = {An efficient and fast model reduced kernel {KNN} for human activity recognition},
	volume = {2021, article no. 2026895},
	journal = {Journal of Advanced Transportation},
	author = {Liu, Zongying and Li, Shaoxi and Hao, Jiangling and Hu, Jingfeng and Pan, Mingyang},
	year = {2021},
	note = {Publisher: Hindawi},
}

@article{khan2022human,
	title = {Human activity recognition via hybrid deep learning based model},
	volume = {22},
	number = {1, article no. 323},
	journal = {Sensors},
	author = {Khan, Imran Ullah and Afzal, Sitara and Lee, Jong Weon},
	year = {2022},
	note = {Publisher: MDPI},
}

@article{yin2008sensor,
	title = {Sensor-based abnormal human-activity detection},
	volume = {20},
	number = {8},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Yin, Jie and Yang, Qiang and Pan, Jeffrey Junfeng},
	year = {2008},
	note = {Publisher: IEEE},
	pages = {1082--1090},
}

@article{li2020review,
	title = {A review of applications in federated learning},
	volume = {149, article no. 106854},
	journal = {Computers \& Industrial Engineering},
	author = {Li, Li and Fan, Yuxi and Tse, Mike and Lin, Kuo-Yi},
	year = {2020},
	note = {Publisher: Elsevier},
}

@article{rustam2020sensor,
	title = {Sensor-based human activity recognition using deep stacked multilayered perceptron model},
	volume = {8},
	journal = {IEEE access : practical innovations, open solutions},
	author = {Rustam, Furqan and Reshi, Aijaz Ahmad and Ashraf, Imran and Mehmood, Arif and Ullah, Saleem and Khan, Dost Muhammad and Choi, Gyu Sang},
	year = {2020},
	note = {Publisher: IEEE},
	pages = {218898--218910},
}

@article{hinton2015distilling,
	title = {Distilling the knowledge in a neural network},
	volume = {2},
	number = {7},
	journal = {arXiv preprint arXiv:1503.02531},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and {others}},
	year = {2015},
}

@inproceedings{ouyang2021clusterfl,
	title = {{ClusterFL}: a similarity-aware federated learning system for human activity recognition},
	booktitle = {Proceedings of the 19th annual international conference on mobile systems, applications, and services},
	author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Huang, Jianwei and Xing, Guoliang},
	year = {2021},
	pages = {54--66},
}

@inproceedings{gudur2021resource,
	title = {Resource-constrained federated learning with heterogeneous labels and models for human activity recognition},
	booktitle = {International workshop on deep learning for human activity recognition},
	author = {Gudur, Gautham Krishna and Perepu, Satheesh Kumar},
	year = {2021},
	note = {tex.organization: Springer},
	pages = {57--69},
}

@article{johnsonWearableDeviceSmartphone2023,
	title = {Wearable device and smartphone data quantify {ALS} progression and may provide novel outcome measures},
	volume = {6},
	copyright = {2023 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00778-y},
	doi = {10.1038/s41746-023-00778-y},
	abstract = {Amyotrophic lateral sclerosis (ALS) therapeutic development has largely relied on staff-administered functional rating scales to determine treatment efficacy. We sought to determine if mobile applications (apps) and wearable devices can be used to quantify ALS disease progression through active (surveys) and passive (sensors) data collection. Forty ambulatory adults with ALS were followed for 6-months. The Beiwe app was used to administer the self-entry ALS functional rating scale-revised (ALSFRS-RSE) and the Rasch Overall ALS Disability Scale (ROADS) surveys every 2–4 weeks. Each participant used a wrist-worn activity monitor (ActiGraph Insight Watch) or an ankle-worn activity monitor (Modus StepWatch) continuously. Wearable device wear and app survey compliance were adequate. ALSFRS-R highly correlated with ALSFRS-RSE. Several wearable data daily physical activity measures demonstrated statistically significant change over time and associations with ALSFRS-RSE and ROADS. Active and passive digital data collection hold promise for novel ALS trial outcome measure development.},
	language = {en},
	number = {1},
	urldate = {2023-03-13},
	journal = {npj Digital Medicine},
	author = {Johnson, Stephen A. and Karas, Marta and Burke, Katherine M. and Straczkiewicz, Marcin and Scheier, Zoe A. and Clark, Alison P. and Iwasaki, Satoshi and Lahav, Amir and Iyer, Amrita S. and Onnela, Jukka-Pekka and Berry, James D.},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Amyotrophic lateral sclerosis, Biomarkers},
	pages = {1--10},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/P5ZT922T/Johnson et al. - 2023 - Wearable device and smartphone data quantify ALS p.pdf:application/pdf},
}

@article{atassiPROACTDatabase2014,
	title = {The {PRO}-{ACT} database},
	volume = {83},
	issn = {0028-3878},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4239834/},
	doi = {10.1212/WNL.0000000000000951},
	abstract = {Objective:
To pool data from completed amyotrophic lateral sclerosis (ALS) clinical trials and create an open-access resource that enables greater understanding of the phenotype and biology of ALS.

Methods:
Clinical trials data were pooled from 16 completed phase II/III ALS clinical trials and one observational study. Over 8 million de-identified longitudinally collected data points from over 8,600 individuals with ALS were standardized across trials and merged to create the Pooled Resource Open-Access ALS Clinical Trials (PRO-ACT) database. This database includes demographics, family histories, and longitudinal clinical and laboratory data. Mixed effects models were used to describe the rate of disease progression measured by the Revised ALS Functional Rating Scale (ALSFRS-R) and vital capacity (VC). Cox regression models were used to describe survival data. Implementing Bonferroni correction, the critical p value for 15 different tests was p = 0.003.

Results:
The ALSFRS-R rate of decline was 1.02 (±2.3) points per month and the VC rate of decline was 2.24\% of predicted (±6.9) per month. Higher levels of uric acid at trial entry were predictive of a slower drop in ALSFRS-R (p = 0.01) and VC (p {\textless} 0.0001), and longer survival (p = 0.02). Higher levels of creatinine at baseline were predictive of a slower drop in ALSFRS-R (p = 0.01) and VC (p {\textless} 0.0001), and longer survival (p = 0.01). Finally, higher body mass index (BMI) at baseline was associated with longer survival (p {\textless} 0.0001).

Conclusion:
The PRO-ACT database is the largest publicly available repository of merged ALS clinical trials data. We report that baseline levels of creatinine and uric acid, as well as baseline BMI, are strong predictors of disease progression and survival.},
	number = {19},
	urldate = {2023-03-13},
	journal = {Neurology},
	author = {Atassi, Nazem and Berry, James and Shui, Amy and Zach, Neta and Sherman, Alexander and Sinani, Ervin and Walker, Jason and Katsovskiy, Igor and Schoenfeld, David and Cudkowicz, Merit and Leitner, Melanie},
	month = nov,
	year = {2014},
	pmid = {25298304},
	pmcid = {PMC4239834},
	pages = {1719--1725},
	file = {PubMed Central Full Text PDF:/Users/gadmohamed/Zotero/storage/46XK39S7/Atassi et al. - 2014 - The PRO-ACT database.pdf:application/pdf},
}

@inproceedings{kimComparingKullbackLeiblerDivergence2021,
	address = {Montreal, Canada},
	title = {Comparing {Kullback}-{Leibler} {Divergence} and {Mean} {Squared} {Error} {Loss} in {Knowledge} {Distillation}},
	isbn = {978-0-9992411-9-6},
	url = {https://www.ijcai.org/proceedings/2021/362},
	doi = {10.24963/ijcai.2021/362},
	abstract = {Knowledge distillation (KD), transferring knowledge from a cumbersome teacher model to a lightweight student model, has been investigated to design efﬁcient neural architectures. Generally, the objective function of KD is the Kullback-Leibler (KL) divergence loss between the softened probability distributions of the teacher model and the student model with the temperature scaling hyperparameter τ . Despite its widespread use, few studies have discussed the inﬂuence of such softening on generalization. Here, we theoretically show that the KL divergence loss focuses on the logit matching when τ increases and the label matching when τ goes to 0 and empirically show that the logit matching is positively correlated to performance improvement in general. From this observation, we consider an intuitive KD loss function, the mean squared error (MSE) between the logit vectors, so that the student model can directly learn the logit of the teacher model. The MSE loss outperforms the KL divergence loss, explained by the difference in the penultimate layer representations between the two losses. Furthermore, we show that sequential distillation can improve performance and that KD, particularly when using the KL divergence loss with small τ , mitigates the label noise. The code to reproduce the experiments is publicly available online at https://github.com/jhoon-oh/kd data/.},
	language = {en},
	urldate = {2023-03-17},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Kim, Taehyeon and Oh, Jaehoon and Kim, Nak Yil and Cho, Sangwook and Yun, Se-Young},
	month = aug,
	year = {2021},
	pages = {2628--2635},
	file = {Kim et al. - 2021 - Comparing Kullback-Leibler Divergence and Mean Squ.pdf:/Users/gadmohamed/Zotero/storage/4TZAKHG4/Kim et al. - 2021 - Comparing Kullback-Leibler Divergence and Mean Squ.pdf:application/pdf},
}

@article{wang2018atomo,
	title = {Atomo: {Communication}-efficient learning via atomic sparsification},
	volume = {31},
	journal = {Advances in Neural Information Processing Systems},
	author = {Wang, Hongyi and Sievert, Scott and Liu, Shengchao and Charles, Zachary and Papailiopoulos, Dimitris and Wright, Stephen},
	year = {2018},
}

@inproceedings{seide1bitStochasticGradient2014,
	title = {1-bit stochastic gradient descent and its application to data-parallel distributed training of speech {DNNs}},
	isbn = {2308457X (ISSN)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910069984&partnerID=40&md5=4830c2e2b87415b1c4c43188a9c8743e},
	abstract = {We show empirically that in SGD training of deep neural networks, one can, at no or nearly no loss of accuracy, quantize the gradients aggressively-to but one bit per value-if the quantization error is carried forward across minibatches (error feedback). This size reduction makes it feasible to parallelize SGD through data-parallelism with fast processors like recent GPUs. We implement data-parallel deterministically distributed SGD by combining this finding with AdaGrad, automatic minibatch-size selection, double buffering, and model parallelism. Unexpectedly, quantization benefits AdaGrad, giving a small accuracy gain. For a typical Switchboard DNN with 46M parameters, we reach computation speeds of 27k frames per second (kfps) when using 2880 samples per minibatch, and 51kfps with 16k, on a server with 8 K20X GPUs. This corresponds to speed-ups over a single GPU of 3.6 and 6.3, respectively. 7 training passes over 309h of data complete in under 7h. A 160M-parameter model training processes 3300h of data in under 16h on 20 dual-GPU servers-a 10 times speed-up-albeit at a small accuracy loss. Copyright © 2014 ISCA.},
	language = {English},
	booktitle = {Proc. {Annu}. {Conf}. {Int}. {Speech}. {Commun}. {Assoc}., {INTERSPEECH}},
	publisher = {International Speech and Communication Association},
	author = {Seide, F. and Fu, H. and Droppo, J. and Li, G. and Yu, D.},
	editor = {{Chng E.S.} and {Li H.} and {Meng H.} and {Ma B.} and {Xie L.}},
	year = {2014},
	note = {Journal Abbreviation: Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH},
	keywords = {Computation speed, Deep neural networks, Double buffering, Frames per seconds, Ion beams, ITS applications, Loss of accuracy, Program processors, Quantization errors, Speech communication, Stochastic gradient descent, Stochastic systems},
	pages = {1058--1062},
	annote = {Export Date: 20 March 2023; Cited By: 422; Conference name: 15th Annual Conference of the International Speech Communication Association: Celebrating the Diversity of Spoken Languages, INTERSPEECH 2014; Conference date: 14 September 2014 through 18 September 2014; Conference code: 108771},
}

@article{konevcny2016federated,
	title = {Federated learning: {Strategies} for improving communication efficiency},
	journal = {arXiv preprint arXiv:1610.05492},
	author = {Konečnỳ, Jakub and McMahan, H Brendan and Yu, Felix X and Richtárik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
	year = {2016},
}

@article{caldas2018expanding,
	title = {Expanding the reach of federated learning by reducing client resource requirements},
	journal = {arXiv preprint arXiv:1812.07210},
	author = {Caldas, Sebastian and Konečny, Jakub and McMahan, H Brendan and Talwalkar, Ameet},
	year = {2018},
}

@article{li2020federated,
	title = {Federated optimization in heterogeneous networks},
	volume = {2},
	journal = {Proceedings of Machine learning and systems},
	author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
	year = {2020},
	pages = {429--450},
}

@article{qu2015quartz,
	title = {Quartz: {Randomized} dual coordinate ascent with arbitrary sampling},
	volume = {28},
	journal = {Advances in neural information processing systems},
	author = {Qu, Zheng and Richtárik, Peter and Zhang, Tong},
	year = {2015},
}

@article{dekel2012optimal,
	title = {Optimal distributed online prediction using mini-batches.},
	volume = {13},
	number = {1},
	journal = {Journal of Machine Learning Research},
	author = {Dekel, Ofer and Gilad-Bachrach, Ran and Shamir, Ohad and Xiao, Lin},
	year = {2012},
}

@article{smith2018cocoa,
	title = {{CoCoA}: {A} general framework for communication-efficient distributed optimization},
	volume = {18},
	journal = {Journal of Machine Learning Research},
	author = {Smith, Virginia and Forte, Simone and Chenxin, Ma and Takáč, Martin and Jordan, Michael I and Jaggi, Martin},
	year = {2018},
	note = {Publisher: MIT press},
	pages = {230},
}

@article{dworkAlgorithmicFoundationsDifferential2014,
	title = {The {Algorithmic} {Foundations} of {Differential} {Privacy}},
	volume = {9},
	issn = {1551-305X, 1551-3068},
	url = {https://www.nowpublishers.com/article/Details/TCS-042},
	doi = {10.1561/0400000042},
	abstract = {The Algorithmic Foundations of Differential Privacy},
	language = {English},
	number = {3–4},
	urldate = {2023-04-06},
	journal = {Foundations and Trends® in Theoretical Computer Science},
	author = {Dwork, Cynthia and Roth, Aaron},
	month = aug,
	year = {2014},
	note = {Publisher: Now Publishers, Inc.},
	pages = {211--407},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/RN3FQM8Q/Dwork and Roth - 2014 - The Algorithmic Foundations of Differential Privac.pdf:application/pdf},
}

@article{fischerHumancomputerInteractionSoftware1989,
	title = {Human-computer interaction software: lessons learned, challenges ahead},
	volume = {6},
	issn = {1937-4194},
	shorttitle = {Human-computer interaction software},
	doi = {10.1109/52.16901},
	abstract = {The author presents a knowledge-based approach to enhance and support communication between humans and computers. His system architecture has an explicit communication channel between the human and the hardware and an implicit communication channel between the human's knowledge base and the computer's stored knowledge. The author uses two intelligent support systems, Framer and Crack, to illustrate this concept. He concludes with a pragmatic description of lessons learned and problems ahead.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Software},
	author = {Fischer, G.},
	month = jan,
	year = {1989},
	note = {Conference Name: IEEE Software},
	keywords = {Board of Directors, Cognition, Displays, Human computer interaction, Keyboards, Software systems, Software tools},
	pages = {44--52},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/YI9AT8QM/16901.html:text/html},
}

@article{lvDeepLearningIntelligent2022,
	title = {Deep {Learning} for {Intelligent} {Human}–{Computer} {Interaction}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/22/11457},
	doi = {10.3390/app122211457},
	abstract = {In recent years, gesture recognition and speech recognition, as important input methods in Human–Computer Interaction (HCI), have been widely used in the field of virtual reality. In particular, with the rapid development of deep learning, artificial intelligence, and other computer technologies, gesture recognition and speech recognition have achieved breakthrough research progress. The search platform used in this work is mainly the Google Academic and literature database Web of Science. According to the keywords related to HCI and deep learning, such as “intelligent HCI”, “speech recognition”, “gesture recognition”, and “natural language processing”, nearly 1000 studies were selected. Then, nearly 500 studies of research methods were selected and 100 studies were finally selected as the research content of this work after five years (2019–2022) of year screening. First, the current situation of the HCI intelligent system is analyzed, the realization of gesture interaction and voice interaction in HCI is summarized, and the advantages brought by deep learning are selected for research. Then, the core concepts of gesture interaction are introduced and the progress of gesture recognition and speech recognition interaction is analyzed. Furthermore, the representative applications of gesture recognition and speech recognition interaction are described. Finally, the current HCI in the direction of natural language processing is investigated. The results show that the combination of intelligent HCI and deep learning is deeply applied in gesture recognition, speech recognition, emotion recognition, and intelligent robot direction. A wide variety of recognition methods were proposed in related research fields and verified by experiments. Compared with interactive methods without deep learning, high recognition accuracy was achieved. In Human–Machine Interfaces (HMIs) with voice support, context plays an important role in improving user interfaces. Whether it is voice search, mobile communication, or children’s speech recognition, HCI combined with deep learning can maintain better robustness. The combination of convolutional neural networks and long short-term memory networks can greatly improve the accuracy and precision of action recognition. Therefore, in the future, the application field of HCI will involve more industries and greater prospects are expected.},
	language = {en},
	number = {22},
	urldate = {2023-04-10},
	journal = {Applied Sciences},
	author = {Lv, Zhihan and Poiesi, Fabio and Dong, Qi and Lloret, Jaime and Song, Houbing},
	month = jan,
	year = {2022},
	note = {Number: 22
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, emotion recognition, gesture recognition, human–computer interaction, speech recognition},
	pages = {11457},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/T6TLDWNB/Lv et al. - 2022 - Deep Learning for Intelligent Human–Computer Inter.pdf:application/pdf},
}

@inproceedings{naseriLocalCentralDifferential2022,
	address = {San Diego, CA, USA},
	title = {Local and {Central} {Differential} {Privacy} for {Robustness} and {Privacy} in {Federated} {Learning}},
	isbn = {978-1-891562-74-7},
	url = {https://www.ndss-symposium.org/wp-content/uploads/2022-54-paper.pdf},
	doi = {10.14722/ndss.2022.23054},
	abstract = {Federated Learning (FL) allows multiple participants to train machine learning models collaboratively by keeping their datasets local while only exchanging model updates. Alas, this is not necessarily free from privacy and robustness vulnerabilities, e.g., via membership, property, and backdoor attacks. This paper investigates whether and to what extent one can use differential Privacy (DP) to protect both privacy and robustness in FL. To this end, we present a first-of-its-kind evaluation of Local and Central Differential Privacy (LDP/CDP) techniques in FL, assessing their feasibility and effectiveness.},
	language = {en},
	urldate = {2023-04-14},
	booktitle = {Proceedings 2022 {Network} and {Distributed} {System} {Security} {Symposium}},
	publisher = {Internet Society},
	author = {Naseri, Mohammad and Hayes, Jamie and De Cristofaro, Emiliano},
	year = {2022},
	file = {Naseri et al. - 2022 - Local and Central Differential Privacy for Robustn.pdf:/Users/gadmohamed/Zotero/storage/BLYBAQLB/Naseri et al. - 2022 - Local and Central Differential Privacy for Robustn.pdf:application/pdf},
}

@misc{LocalCentralDifferential,
	title = {Local and {Central} {Differential} {Privacy} for {Robustness} and {Privacy} in {Federated} {Learning}},
	url = {https://www.ndss-symposium.org/ndss-paper/auto-draft-204/},
	language = {en-US},
	urldate = {2023-04-14},
	journal = {NDSS Symposium},
	file = {Snapshot:/Users/gadmohamed/Zotero/storage/2EACNWTW/auto-draft-204.html:text/html},
}

@misc{EvaluatingDifferentiallyPrivate,
	title = {Evaluating {Differentially} {Private} {Machine} {Learning} in {Practice} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/usenixsecurity19/presentation/jayaraman},
	urldate = {2023-07-14},
	file = {Evaluating Differentially Private Machine Learning in Practice | USENIX:/Users/gadmohamed/Zotero/storage/XLEC52CG/jayaraman.html:text/html},
}

@inproceedings{carliniSecretSharerEvaluating2019,
	title = {The {Secret} {Sharer}: {Evaluating} and {Testing} {Unintended} {Memorization} in {Neural} {Networks}},
	isbn = {978-1-939133-06-9},
	shorttitle = {The {Secret} {Sharer}},
	url = {https://www.usenix.org/conference/usenixsecurity19/presentation/carlini},
	language = {en},
	urldate = {2023-07-14},
	author = {Carlini, Nicholas and Liu, Chang and Erlingsson, Úlfar and Kos, Jernej and Song, Dawn},
	year = {2019},
	pages = {267--284},
	file = {Full Text PDF:/Users/gadmohamed/Zotero/storage/WFJ576RJ/Carlini et al. - 2019 - The Secret Sharer Evaluating and Testing Unintend.pdf:application/pdf},
}

@inproceedings{mironovRenyiDifferentialPrivacy2017,
	title = {Rényi {Differential} {Privacy}},
	doi = {10.1109/CSF.2017.11},
	abstract = {We propose a natural relaxation of differential privacy based on the Rényi divergence. Closely related notions have appeared in several recent papers that analyzed composition of differentially private mechanisms. We argue that the useful analytical tool can be used as a privacy definition, compactly and accurately representing guarantees on the tails of the privacy loss.We demonstrate that the new definition shares many important properties with the standard definition of differential privacy, while additionally allowing tighter analysis of composite heterogeneous mechanisms.},
	booktitle = {2017 {IEEE} 30th {Computer} {Security} {Foundations} {Symposium} ({CSF})},
	author = {Mironov, Ilya},
	month = aug,
	year = {2017},
	note = {ISSN: 2374-8303},
	keywords = {Additives, Computer security, Databases, differential privacy, Google, Privacy, renyi divergence, Standards, Tools},
	pages = {263--275},
	file = {IEEE Xplore Abstract Record:/Users/gadmohamed/Zotero/storage/JUKFUIM3/8049725.html:text/html;IEEE Xplore Full Text PDF:/Users/gadmohamed/Zotero/storage/7IGG88BY/Mironov - 2017 - Rényi Differential Privacy.pdf:application/pdf},
}

@misc{TransactionsDataPrivacy,
	title = {Transactions on {Data} {Privacy}},
	url = {http://www.tdp.cat/issues16/abs.a289a17.php},
	urldate = {2023-07-14},
	file = {Transactions on Data Privacy:/Users/gadmohamed/Zotero/storage/HSENI85D/abs.a289a17.html:text/html},
}

@article{rahmanmia,
	title = {Membership inference attack against differentially private deep learning model},
	volume = {11},
	journal = {Transactions on Data Privacy},
	author = {Rahman, M.A. and Rahman, Thohedur and Laganière, R. and Mohammed, Neimat and Wang, Y.},
	month = apr,
	year = {2018},
	pages = {61--79},
}
